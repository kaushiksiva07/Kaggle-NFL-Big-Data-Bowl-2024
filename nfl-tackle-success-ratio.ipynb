{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":60305,"databundleVersionId":6654553,"sourceType":"competition"}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **<center><span style=\"color:RebeccaPurple;\">Player Tackle Analysis</span></center>**\n***","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix,roc_curve, roc_auc_score, precision_recall_curve, auc\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nimport xgboost as xgb\nfrom scipy.spatial.distance import cdist, euclidean\nfrom sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, StratifiedKFold, learning_curve,  cross_val_score\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy.stats import uniform, randint\nfrom sklearn.calibration import calibration_curve\npd.options.display.float_format = '{:.2f}'.format","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-30T20:14:40.906183Z","iopub.execute_input":"2023-12-30T20:14:40.906937Z","iopub.status.idle":"2023-12-30T20:14:44.152471Z","shell.execute_reply.started":"2023-12-30T20:14:40.906897Z","shell.execute_reply":"2023-12-30T20:14:44.151074Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Game Data\ngame_data = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2024/games.csv')\n\n# Player Data\nplayer_data = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2024/players.csv')\nplayer_data[['feet', 'inches']] = player_data['height'].str.split('-', expand=True)\nplayer_data['total_inches'] = player_data['feet'].astype(int) * 12 + player_data['inches'].astype(int)\n\n# Play Data\nplay_data = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2024/plays.csv')\nplay_data = play_data.rename(columns={'ballCarrierId': 'nflId'})\n\n# Tackle Data\ntackle_data = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2024/tackles.csv')\n\n# Combine tackles, assists, and forced fumbles into one category\ntackle_data['success'] = tackle_data[['tackle', 'assist', 'forcedFumble']].max(axis=1)\ntackle_data = tackle_data[['gameId', 'playId', 'nflId', 'success']]\n\n# Tracking Data\ntrack = []\nfor i in range(1, 10):\n    df = pd.read_csv(f'/kaggle/input/nfl-big-data-bowl-2024/tracking_week_{i}.csv')\n    df.insert(0, 'week', i)\n    track.append(df)\ntrack = pd.concat(track)\ntrack.head()\n\n# Separate Players Into Offense and Defense\noff_pos = ['QB', 'T', 'TE', 'WR', 'G', 'RB', 'C', 'FB', 'LS']\ndef_pos = ['DE', 'NT', 'SS', 'FS', 'OLB', 'DT', 'CB', 'ILB', 'MLB', 'DB']\n\noff_players = player_data.loc[player_data['position'].isin(off_pos)]['nflId']\ndef_players = player_data.loc[player_data['position'].isin(def_pos)]['nflId']\n\n# Create Player Tackle Data\ntackle_sum = tackle_data.groupby('nflId').agg(success_sum=('success', 'sum'), opportunities_count=('gameId', 'count')).reset_index()\ntackle_final = pd.merge(tackle_sum, player_data, on='nflId')\n\n# Aggregate Positions\ntackle_final.loc[tackle_final['position'] == 'MLB', 'position'] = 'ILB'\ntackle_final.loc[tackle_final['position'] == 'NT', 'position'] = 'DT'\ntackle_final.loc[tackle_final['position'].isin(['FS', 'SS']), 'position'] = 'S'\ntackle_final.loc[tackle_final['position'] == 'DB', 'position'] = 'S'","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-12-30T20:14:44.154589Z","iopub.execute_input":"2023-12-30T20:14:44.155112Z","iopub.status.idle":"2023-12-30T20:15:36.091699Z","shell.execute_reply.started":"2023-12-30T20:14:44.155076Z","shell.execute_reply":"2023-12-30T20:15:36.090395Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Measuring tackling proficiency in the NFL seems straightforward at first glance – a player amassing a high number of tackles would typically be viewed as a standout tackler. However, relying solely on box-score metrics to evaluate tackling prowess presents a set of challenges:\n1. **Volume Bias**: Tackling stats are often volume-based, favoring players who are consistently on the field. This creates a bias where frequent participation can inflate tackling numbers.\n2. **Positional Disparity**: Certain positions, such as Inside Linebackers (ILB), tend to accrue higher tackle counts due to their positioning. This disparity skews the perceived tackling abilities of players in less favored positions, such as Defensive Ends (DE).\n3. **Situational Differences**: Box-score metrics offer no insights into the difficulty or context of each tackle, failing to differentiate between routine and exceptional tackles.\n\nIn this project, we aim to address the limitations associated with evaluating tackling prowess in the NFL. We're leveraging a predictive model that factors in various contextual elements to estimate the likelihood of successfully completing a tackle against a pass catcher. By incorporating these contextual factors, our goal is to refine the assessment of defensive capabilities and provide a more comprehensive understanding of player performance in tackling scenarios.","metadata":{}},{"cell_type":"markdown","source":"# **<center><span style=\"color:RebeccaPurple;\">Player Tackle Analysis</span></center>**\n***","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(19, 6))\n\n# Top 20 Players by Number of Tackles by position\npos_count = tackle_final.groupby('position')['nflId'].count()\nbars1 = pos_count.sort_values().plot(kind='barh', color='#6A0DAD', ax=axes[0])\nbars1.set_title('Number of Players by Position')\nbars1.set_xlabel('Number of Players')\nbars1.set_ylabel('Position')\nfor index, value in enumerate(pos_count.sort_values()):\n    bars1.text(value, index, str(value), ha='left', va='center', color='black', fontsize=7)\n\n# Top 20 Players by Number of Tackles by position\ntop_positions = tackle_final.groupby('position')['success_sum'].sum()\nbars2 = top_positions.sort_values().plot(kind='barh', color='#6A0DAD', ax=axes[1])\nbars2.set_title('Number of Tackles by Position')\nbars2.set_xlabel('Number of Tackles')\nbars2.set_ylabel('Position')\nfor index, value in enumerate(top_positions.sort_values()):\n    bars2.text(value, index, str(value), ha='left', va='center', color='black', fontsize=6)\n\n# Average Number of tackles by Position\nadj_pos = top_positions / pos_count\nbars3 = adj_pos.sort_values().plot(kind='barh', color='#6A0DAD', ax=axes[2])\nbars3.set_title('Average Number of Tackles by Position')\nbars3.set_xlabel('Number of Tackles')\nbars3.set_ylabel('Position')\nfor index, value in enumerate(adj_pos.sort_values()):\n    bars3.text(value, index, str(round(value, 2)), ha='left', va='center', color='black', fontsize=6)\n\nplt.tight_layout()\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-30T20:15:36.093208Z","iopub.execute_input":"2023-12-30T20:15:36.093575Z","iopub.status.idle":"2023-12-30T20:15:37.051303Z","shell.execute_reply.started":"2023-12-30T20:15:36.093543Z","shell.execute_reply":"2023-12-30T20:15:37.050238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The plots above demonstrate intriguing insights into the distribution of tackles across different positions. Cornerbacks (CB) emerge with the most significant number of players, followed by the second-highest total tackles, subsequently leading to the third-highest tackles-per-player ratio. Contrastingly, Inside Linebackers (ILB), possess the fewest players while displaying the highest tackle rate per player. These visuals underscore a compelling observation: positions with a higher count of players tend to accumulate more tackles owing to increased opportunities, influencing the overall tackle statistics. Moreover, the data highlights notable trends in positions like Inside Linebackers (ILB), Safeties (S), and Cornerbacks (CB), showcasing their higher tackle rates. This aligns with the understanding that specific positions often find themselves in situations conducive to potential tackles, thus encountering more opportunities for tackling and consequently recording a higher count of completed tackles. Such insights reveal how a player's position on the field directly correlates with their likelihood of engaging in tackling scenarios. Ultimately, these statistics neglect the contextual nuances of tackles, such as the ball carrier's position in open space relative to the defenders or the presence of blockers hindering the tackle attempts.","metadata":{}},{"cell_type":"markdown","source":"# **<center><span style=\"color:RebeccaPurple;\">Feature Engineering</span></center>**\n***","metadata":{}},{"cell_type":"markdown","source":"To enhance the understanding of factors influencing successful tackles, several key features were engineered:\n1. `blockers`: A binary indicator (1 for presence, 0 for absence) denoting the presence of blockers. Expectantly, the probability of a successful tackle decreases in the presence of blockers as they impede a defender's ability to tackle.\n2. `tack_side`: A binary indicator (1 for in front, 0 for behind) signifying the positioning of the defender concerning the pass catcher. Tackling from the front is intuitively perceived as easier than tackling from behind.\n3. `pos_diff`: A continuous positive value representing the Euclidean distance between the pass catcher and the defender. A shorter distance indicates higher odds of completing a tackle.\n4. `speed_diff`: A continuous value indicating the difference in speed between the pass catcher and the defender. A faster defender relative to the pass catcher may increase the likelihood of completing a tackle due to catching up.\n5. `rel_angle`: A continuous value reflecting the relative angle between the pass catcher and the defender. Favorable angles, where both face each other, might increase the tackle probability compared to opposing directions.\n6. `car_sideline`: A continuous value indicating the pass catcher's distance from the nearest sideline. Tackling near a sideline might facilitate easier tackles compared to tackles in the middle of the field.\n7. `weight_dif`: A continuous value expressing the weight difference between the pass catcher and the defender. If the defender is heavier for example, it might be harder for the pass catcher to break a tackle, leading to a higher probability of completing a tackle.\n8. `total_inches_tack`:  A continuous value representing the height of the defender. Shorter defenders might have an advantage as they can position themselves lower for better tackling success.","metadata":{}},{"cell_type":"code","source":"# Subset data to time of catch\ncatch = track.loc[(track['event'] == 'pass_outcome_caught') & (track['nflId'].notnull())]\n\n# Add tackle outcome \ncatch = pd.merge(catch, tackle_data, on = ['gameId', 'playId', 'nflId'], how = 'left')\ncatch['success'] = catch['success'].notnull().astype('int')\n\n# Ball Carrier Data\ncarrier = play_data[['gameId', 'playId', 'nflId', 'ballCarrierDisplayName']]\n\n# Add whether player had ball or not\ncatch = pd.merge(catch, carrier, on = ['gameId', 'playId', 'nflId'], how = 'left')\ncatch['ballCarrierDisplayName'] = catch['ballCarrierDisplayName'].notnull().astype('int')\ncatch = catch[['gameId', 'playId', 'nflId', 'x', 'y', 's', 'a',\n            'dis', 'o', 'dir', 'success', 'ballCarrierDisplayName', 'playDirection']]\n\n# Ball Carriers\ncarr = catch.loc[(catch['nflId'].isin(off_players)) & catch['ballCarrierDisplayName'] == 1]\ncarr = carr[['gameId', 'playId', 'nflId', 'x', 'y', 's', 'a', 'dis', 'o', 'dir', 'playDirection']]\n\n# Defenders\ndefender = catch.loc[catch['nflId'].isin(def_players)]\ndefender = defender[['gameId', 'playId', 'nflId', 'x', 'y', 's', 'a', 'dis', 'o', 'dir', 'success']]\n\n# Merge defender and carrier data \nfinal = pd.merge(defender, carr, on = ['gameId', 'playId'], suffixes=('_tack', '_car'), how = 'left')\n\n# Determine whether there is a defender who can block\nblocks = catch.loc[(catch['nflId'].isin(off_players)) & catch['ballCarrierDisplayName'] == 0]\nblocks.reset_index(drop=True)\nblockers = []\n\nfor _, row_a in final.iterrows():\n    # Extract coordinates for carrier and tackler\n    player1_coords = (row_a['x_car'], row_a['y_car'])\n    player2_coords = (row_a['x_tack'], row_a['y_tack'])\n    \n    # Filter blockers based on gameId and playId\n    df_b_filtered = blocks[(blocks['gameId'] == row_a['gameId']) & (blocks['playId'] == row_a['playId'])]\n    \n    # Check conditions for each row in filtered blockers\n    found_blocker = any(\n        (row_b['x'] > min(player1_coords[0], player2_coords[0])) and\n        (row_b['x'] < max(player1_coords[0], player2_coords[0])) and\n        (euclidean(player1_coords, (row_b['x'], row_b['y'])) < euclidean(player1_coords, player2_coords))\n        for _, row_b in df_b_filtered.iterrows()\n    )\n    \n    # Assign 1 if condition is met, otherwise 0\n    blockers.append(1 if found_blocker else 0)\n\n# Features    \n\n# Presence of blocker\nfinal['blockers'] = blockers\n\n# 1 if defender is in front of the ball carrier, 0 else\ndef def_side(row):\n    if row['playDirection'] == 'right' and row['x_tack'] > row['x_car']:\n        return 1\n    elif row['playDirection'] == 'right' and row['x_tack'] <= row['x_car']:\n        return 0\n    elif row['playDirection'] == 'left' and row['x_tack'] < row['x_car']:\n        return 1\n    elif row['playDirection'] == 'left' and row['x_tack'] >= row['x_car']:\n        return 0\n        \nfinal['tack_side'] = final.apply(def_side, axis=1)\n\n# Position Difference\nfinal['pos_diff'] = np.sqrt((final['x_tack'] - final['x_car'])**2 + (final['y_tack'] - final['y_car'])**2)\n\n# Speed Difference\nfinal['speed_diff'] = final['s_tack'] - final['s_car']\n\n# Relative Angle\nfinal['rel_angle'] = np.abs(final['o_car'] - final['o_tack'])\nfinal.replace([np.inf, -np.inf], 0, inplace=True)\n\n# Distance from nearest sideline\nfinal['car_sideline'] = np.where(final['y_car'] >= (53.3 / 2), 53.3 - final['y_car'], final['y_car'])\n\n    \n# Height and Weight\nfinal = pd.merge(final, player_data[['nflId', 'weight', 'total_inches']], left_on='nflId_tack', right_on='nflId', how='left')\nfinal.rename(columns={'weight': 'weight_tack', 'total_inches': 'total_inches_tack'}, inplace=True)\nfinal.drop('nflId', axis=1, inplace=True)\n\nfinal = pd.merge(final, player_data[['nflId', 'weight', 'total_inches']], left_on='nflId_car', right_on='nflId', how='left')\nfinal.rename(columns={'weight': 'weight_car', 'total_inches': 'total_inches_car'}, inplace=True)\nfinal.drop('nflId', axis=1, inplace=True)\n\n# Weight Difference\nfinal['weight_dif'] = final['weight_tack'] - final['weight_car']\n\nfinal.head()\n","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2023-12-30T20:15:37.054078Z","iopub.execute_input":"2023-12-30T20:15:37.054468Z","iopub.status.idle":"2023-12-30T20:17:49.293928Z","shell.execute_reply.started":"2023-12-30T20:15:37.054433Z","shell.execute_reply":"2023-12-30T20:17:49.292253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **<center><span style=\"color:RebeccaPurple;\">Feature Analysis</span></center>**\n***","metadata":{}},{"cell_type":"markdown","source":"Here are visualizations depicting the distributions of the above engineered features, showcasing the distinction between successful and unsuccessful tackles for comparative analysis.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\n\nplt.subplot(2, 2, 1)  # First subplot\nsns.kdeplot(x=final['rel_angle'], hue = final['success'], palette = {0: '#6A0DAD', 1: '#FFD700'})\nplt.title('Relative Angle by Tackle Success')\nplt.xlabel('Relative Angle')\nplt.legend(title='Completed Tackle', labels=['Yes', 'No'])\n\nplt.subplot(2, 2, 2)  # Second subplot\nsns.kdeplot(x=final['pos_diff'], hue = final['success'], palette = {0: '#6A0DAD', 1: '#FFD700'})\nplt.title('Positional Difference by Tackle Success')\nplt.xlabel('Positional Difference')\nplt.legend(title='Completed Tackle', labels=['Yes', 'No'])\n\nplt.subplot(2, 2, 3)  # Third subplot\nsns.kdeplot(x=final['speed_diff'], hue = final['success'], palette = {0: '#6A0DAD', 1: '#FFD700'})\nplt.title('Speed Difference by Tackle Success')\nplt.xlabel('Speed Difference')\nplt.legend(title='Completed Tackle', labels=['Yes', 'No'])\n\nplt.subplot(2, 2, 4)  # Fourth subplot\nsns.kdeplot(x=final['car_sideline'], hue = final['success'], palette = {0: '#6A0DAD', 1: '#FFD700'})\nplt.title('Weight Difference by Tackle Success')\nplt.xlabel('Ball Carrier Distance From Sidline')\nplt.legend(title='Completed Tackle', labels=['Yes', 'No'])\n\nplt.tight_layout()\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-30T20:17:49.295821Z","iopub.execute_input":"2023-12-30T20:17:49.296358Z","iopub.status.idle":"2023-12-30T20:17:52.129767Z","shell.execute_reply.started":"2023-12-30T20:17:49.296303Z","shell.execute_reply":"2023-12-30T20:17:52.129026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8, 6))\n\nplt.subplot(2, 2, 1)  # First subplot\nsns.histplot(final, x='success', hue='blockers',\n    multiple=\"fill\", stat=\"proportion\",\n    discrete=True, shrink=.8, palette = {0: '#6A0DAD', 1: '#FFD700'})\nplt.title('Presence of Blocker')\nplt.xlabel('Completed Tackle')\nplt.legend(title='Blocker', labels=['Yes', 'No'])\nplt.xticks([0, 1], ['No', 'Yes'])\n\nplt.subplot(2, 2, 2)  # Second subplot\nsns.histplot(final, x='success', hue='tack_side',\n    multiple=\"fill\", stat=\"proportion\",\n    discrete=True, shrink=.8, palette = {0: '#6A0DAD', 1: '#FFD700'})\nplt.title('Which Side is the Defender On?')\nplt.xlabel('Completed Tackle')\nplt.legend(title='Side', labels=['Front', 'Behind'])\nplt.xticks([0, 1], ['No', 'Yes'])\n\nplt.subplot(2, 2, 3)  # Third subplot\nsns.boxplot(x='success', y='weight_dif', data=final, palette = {0: '#6A0DAD', 1: 'yellow'})\nplt.title('Weight Difference by Tackle Success')\nplt.xlabel('Completed Tackle')\nplt.ylabel('Weight Difference')\nplt.xticks([0, 1], ['No', 'Yes'])\n\nplt.subplot(2, 2, 4)  # Fourth subplot\nsns.boxplot(x='success', y='total_inches_tack', data=final, palette = {0: '#6A0DAD', 1: 'yellow'})\nplt.title('Tackler Height by Tackle Success')\nplt.xlabel('Completed Tackle')\nplt.ylabel('Height')\nplt.xticks([0, 1], ['No', 'Yes'])\n\nplt.tight_layout()\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-30T20:17:52.130832Z","iopub.execute_input":"2023-12-30T20:17:52.131201Z","iopub.status.idle":"2023-12-30T20:17:53.418861Z","shell.execute_reply.started":"2023-12-30T20:17:52.131167Z","shell.execute_reply":"2023-12-30T20:17:53.417847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The plots illustrate a distinct divergence in distributions between successful and unsuccessful tackles. Notably, disparities are prominent in positional discrepancies, speed variations, blocker presence, the defender's positioning concerning the pass catcher, and disparities in height. While the relative angle and weight differences showcase some variance, the emphasis is on larger dispersions in the unsuccessful tackle distributions, particularly evident in the weight difference—an observation depicted both as a density plot and box plot. In summary, the discernible disparities within the distributions for each chosen feature signify their relevance as impactful attributes for our model.","metadata":{}},{"cell_type":"markdown","source":"# **<center><span style=\"color:RebeccaPurple;\">Finding the Best Model</span></center>**\n***","metadata":{}},{"cell_type":"markdown","source":"Here, we assess various algorithms for predicting the probability of completing a tackle, employing methods such as Logistic Regression, Random Forest, Gradient Boosting, and XGBoost. To gauge the performance of these models in our predictions, we measure several key metrics including accuracy, precision, recall, F1 Score, and present a Confusion Matrix.","metadata":{}},{"cell_type":"code","source":"features = ['blockers', 'pos_diff', 'speed_diff', 'tack_side', 'rel_angle', 'car_sideline', 'weight_dif',\n           'total_inches_tack']\n\nX = final[features]\ny = final['success']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1234)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-30T20:17:53.420336Z","iopub.execute_input":"2023-12-30T20:17:53.421274Z","iopub.status.idle":"2023-12-30T20:17:53.451765Z","shell.execute_reply.started":"2023-12-30T20:17:53.421227Z","shell.execute_reply":"2023-12-30T20:17:53.450166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <span style=\"color:RebeccaPurple;\">Logistic Regression</span>","metadata":{}},{"cell_type":"code","source":"lr = LogisticRegression(max_iter=650)\nlr.fit(X_train, y_train)\n\ny_pred = lr.predict(X_test)\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Precision:\", precision_score(y_test, y_pred))\nprint(\"Recall:\", recall_score(y_test, y_pred))\nprint(\"F1 Score:\", f1_score(y_test, y_pred))\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(y_test, y_pred))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-30T20:17:53.453520Z","iopub.execute_input":"2023-12-30T20:17:53.454014Z","iopub.status.idle":"2023-12-30T20:17:53.985856Z","shell.execute_reply.started":"2023-12-30T20:17:53.453951Z","shell.execute_reply":"2023-12-30T20:17:53.984359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <span style=\"color:RebeccaPurple;\">Random Forest</span>","metadata":{}},{"cell_type":"code","source":"rf = RandomForestClassifier(n_estimators=100, random_state=1234)\nrf.fit(X_train, y_train)\n\ny_pred = rf.predict(X_test)\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Precision:\", precision_score(y_test, y_pred))\nprint(\"Recall:\", recall_score(y_test, y_pred))\nprint(\"F1 Score:\", f1_score(y_test, y_pred))\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(y_test, y_pred))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-30T20:17:53.988426Z","iopub.execute_input":"2023-12-30T20:17:53.989310Z","iopub.status.idle":"2023-12-30T20:18:00.667821Z","shell.execute_reply.started":"2023-12-30T20:17:53.989238Z","shell.execute_reply":"2023-12-30T20:18:00.666576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <span style=\"color:RebeccaPurple;\">Gradient Boosting<span>","metadata":{}},{"cell_type":"code","source":"gb = GradientBoostingClassifier(n_estimators=100, random_state=1234)  # Adjust hyperparameters as needed\ngb.fit(X_train, y_train)\n\ny_pred = gb.predict(X_test)\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Precision:\", precision_score(y_test, y_pred))\nprint(\"Recall:\", recall_score(y_test, y_pred))\nprint(\"F1 Score:\", f1_score(y_test, y_pred))\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(y_test, y_pred))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-30T20:18:00.671642Z","iopub.execute_input":"2023-12-30T20:18:00.671996Z","iopub.status.idle":"2023-12-30T20:18:07.757284Z","shell.execute_reply.started":"2023-12-30T20:18:00.671952Z","shell.execute_reply":"2023-12-30T20:18:07.756074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <span style=\"color:RebeccaPurple;\">XGBoost<span>","metadata":{}},{"cell_type":"code","source":"xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=1234)\nxgb_model.fit(X_train, y_train)\n\ny_pred = xgb_model.predict(X_test)\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Precision:\", precision_score(y_test, y_pred))\nprint(\"Recall:\", recall_score(y_test, y_pred))\nprint(\"F1 Score:\", f1_score(y_test, y_pred))\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(y_test, y_pred))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-30T20:18:07.758678Z","iopub.execute_input":"2023-12-30T20:18:07.759642Z","iopub.status.idle":"2023-12-30T20:18:08.160576Z","shell.execute_reply.started":"2023-12-30T20:18:07.759606Z","shell.execute_reply":"2023-12-30T20:18:08.159450Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Throughout these model evaluations, overall accuracy remained relatively consistent. However, this metric wasn't deemed the most suitable due to the significant class imbalance – there are notably more negative observations than positive ones. This mirrors real-world scenarios, where only a single player can make a tackle amidst 11 defensive players on the field. Consequently, we focused on precision and recall, aiming to minimize false positives and false negatives, respectively. Since our ultimate goal is to evaluate player tackling performance, both precision and recall are crucial. Hence, we primarily relied on the F1 Score as it offers a balanced view of these metrics. Given the prevalence of negative examples, our priority was to reduce false negatives. Across models, logistic regression yielded the lowest F1 Score, as anticipated in an imbalanced dataset, while XGBoost showcased the highest F1 Score. This aligns with the XGBoost confusion matrix, illustrating the fewest false negatives among the models evaluated.","metadata":{}},{"cell_type":"markdown","source":"# **<center><span style=\"color:RebeccaPurple;\">Optimize Parameters Using RandomSearchCV</span></center>**\n***","metadata":{}},{"cell_type":"markdown","source":"In this phase, we executed a Random Search on hyperparameters to fine-tune our XGBoost model resulting in fewer false positives and false negatives. Despite observing marginal improvements, these refinements hold significance and promise for enhancing model performance.","metadata":{}},{"cell_type":"code","source":"cv_grid = {'max_depth': randint(2,6), \n           'min_child_weight': randint(1,4),\n          'subsample': uniform(0.6, 0.4), \n            'max_delta_step': randint(0,10),\n          'learning_rate': uniform(0.05,0.35)}\nk = StratifiedKFold(n_splits=5)\ncsv = RandomizedSearchCV(xgb.XGBClassifier(objective=\"binary:logistic\", random_state=1234), cv_grid, scoring = 'roc_auc', cv = k)\n\ncsv.fit(X_train, y_train)\n\nxgb_model = xgb.XGBClassifier(**csv.best_params_)\nxgb_model.fit(X_train, y_train)\n\nprint('Optimal Parameters:')\nprint(csv.best_params_)\nprint()\ny_pred = xgb_model.predict(X_test)\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Precision:\", precision_score(y_test, y_pred))\nprint(\"Recall:\", recall_score(y_test, y_pred))\nprint(\"F1 Score:\", f1_score(y_test, y_pred))\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(y_test, y_pred))\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-30T20:18:08.162305Z","iopub.execute_input":"2023-12-30T20:18:08.162740Z","iopub.status.idle":"2023-12-30T20:18:19.059066Z","shell.execute_reply.started":"2023-12-30T20:18:08.162697Z","shell.execute_reply":"2023-12-30T20:18:19.057901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **<center><span style=\"color:RebeccaPurple;\">Model Analysis</span></center>**\n***","metadata":{}},{"cell_type":"markdown","source":"In this section, we delve into a comprehensive evaluation of our predictive model. Rigorous assessment is important for gauging the model's efficacy,so we investigate multiple facets of its performance. Through various visualizations and metrics, we aim to dissect the predictive prowess, understand its behavior across different scenarios, and highlight key factors driving its decisions. The evaluation encompasses several characteristics, from the discriminative capacity brought by ROC curves and precision-recall curves to the crucial insights provided by a feature importance plot and the model's learning trajectory seen through learning curve plots.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 4))\n\nplt.subplot(1, 2, 1)  # First subplot\n# ROC Curve\ny_scores = xgb_model.predict_proba(X_val)[:, 1] \nfpr, tpr, thresholds = roc_curve(y_val, y_scores)\nplt.plot(fpr, tpr, label='ROC Curve (AUC = {:.2f})'.format(roc_auc_score(y_val, y_scores)), color='#6A0DAD')\nplt.plot([0, 1], [0, 1], linestyle='--', label='Random', color='#FFD700')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend()\n\nplt.subplot(1, 2, 2)  # Second subplot\n# Precision-Recall Curve\nprecision, recall, thresholds = precision_recall_curve(y_val, y_scores)\nplt.plot(recall, precision, label='Precision-Recall Curve (AUC = {:.2f})'.format(auc(recall, precision)), color='#6A0DAD')\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Precision-Recall Curve')\nplt.legend()\n\nplt.tight_layout()\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-30T20:18:19.060803Z","iopub.execute_input":"2023-12-30T20:18:19.061487Z","iopub.status.idle":"2023-12-30T20:18:19.777074Z","shell.execute_reply.started":"2023-12-30T20:18:19.061444Z","shell.execute_reply":"2023-12-30T20:18:19.775953Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n\n# Feature Importance\nxgb.plot_importance(xgb_model, color='#6A0DAD', ax=axes[0])\naxes[0].set_title(\"XGBoost Feature Importance\")\n\n# Learning Curve\ntrain_sizes, train_scores, test_scores = learning_curve(\n    xgb_model, X, y, cv=k, scoring='roc_auc', train_sizes=np.linspace(0.1, 1.0, 10)\n)\ntrain_scores_mean = np.mean(train_scores, axis=1)\ntrain_scores_std = np.std(train_scores, axis=1)\ntest_scores_mean = np.mean(test_scores, axis=1)\ntest_scores_std = np.std(test_scores, axis=1)\n\naxes[1].fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"blue\")\naxes[1].fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"orange\")\naxes[1].plot(train_sizes, train_scores_mean, 'o-', color='#6A0DAD', label=\"Training score\")\naxes[1].plot(train_sizes, test_scores_mean, 'o-', color='#FFD700', label=\"Cross-validation score\")\naxes[1].set_xlabel(\"Training examples\")\naxes[1].set_ylabel(\"Score\")\naxes[1].legend(loc=\"best\")\naxes[1].set_title(\"Learning Curve\")\n\nplt.tight_layout()\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-30T20:18:19.778822Z","iopub.execute_input":"2023-12-30T20:18:19.779557Z","iopub.status.idle":"2023-12-30T20:18:30.908141Z","shell.execute_reply.started":"2023-12-30T20:18:19.779501Z","shell.execute_reply":"2023-12-30T20:18:30.907074Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1. The ROC curve (top-left) visually represents the trade-off between true positive rate and false positive rate across different threshold values. A curve closer to the upper-left corner of the plot indicates better performance, indicating higher True Positive Rate (TPR) while maintaining lower False Positive Rate (FPR). Additionally, the area under the ROC curve (AUC-ROC) quantifies the model's performance; a higher AUC value (closer to 1) suggests better discrimination between positive and negative classes. In essence, the ROC curve helps in assessing the model's ability to distinguish between classes across varying thresholds, aiding in selecting the optimal threshold for your specific use case. Our model has an AUC-RUC of 0.93, which suggests that the model has strong predictive power, as it can separate the classes well. It implies that there's a 93% chance that the model will be able to distinguish between successful and unsuccessful tackles.\n\n2. The precision-recall curve (top-right) evaluates a model's performance by showing how well it balances precision (the ability to avoid false positives) and recall (the ability to find all positive instances) at different thresholds. Here, an AUC of 0.7 indicates that the model performs reasonably well but might have some limitations in its precision-recall trade-off. It suggests that the model is moderately successful in identifying relevant instances (recall) while maintaining a decent level of precision.\n\n3. The feature importance plot (bottom-left) gives us insight into how impactful each feature that we included is on the model's prediction. A higher importance would indicate a more substantial impact on the model's predictions. Here, we see that the distance between the pass catcher and the defender of interest is the most important feature. This is in line with our expectations as this is typically the most obvious indicator when determining whether a defender can make a tackle. \n\n4. The learning curve plot (bottom-right) helps us better understand the model's performance concerning the dataset size. As we can see, we see a narrowing in the gab between the training and cross-validation curves. This would suggest better generalization, indicating that the model is not overfitting, which is exaclty what we want.","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">While the default threshold probabilty for predicting positive examples is 0.5, this may not necessarily be the best threshold for an inbalanced dataset. Below we compute the optimal threshold probability, which results in great performance from our model on the validation set.</div>","metadata":{}},{"cell_type":"code","source":"# Predicted Probabilities\npredicted_probabilities = xgb_model.predict_proba(X_test)[:, 1]\n\n# Define a range of thresholds (0.1 to 0.9 with step 0.1)\nthresholds = np.arange(0.1, 1.0, 0.1)\nf1_scores = []\nbest_threshold = None\nbest_f1_score = 0\n\n# Calculate precision and recall for each threshold\nfor threshold in thresholds:\n    y_pred = (predicted_probabilities > threshold).astype(int)\n    precision = precision_score(y_test, y_pred)\n    recall = recall_score(y_test, y_pred)\n    f1 = 2 * (precision * recall) / (precision + recall + 1e-10)\n    f1_scores.append(f1)# F1-score calculation\n    if f1 > best_f1_score:\n        best_f1_score = f1\n        best_threshold = threshold\n# Print Optimal Threshold Probability      \nprint(f\"Best threshold: {best_threshold:.2f}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-12-30T20:18:30.909860Z","iopub.execute_input":"2023-12-30T20:18:30.910273Z","iopub.status.idle":"2023-12-30T20:18:31.042199Z","shell.execute_reply.started":"2023-12-30T20:18:30.910238Z","shell.execute_reply":"2023-12-30T20:18:31.041030Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"probs = xgb_model.predict_proba(X_val)[:, 1]\nprobs[probs > best_threshold] = 1\nprint(\"Accuracy:\", accuracy_score(y_val, probs.astype(int)))\nprint(\"Precision:\", precision_score(y_val, probs.astype(int)))\nprint(\"Recall:\", recall_score(y_val, probs.astype(int)))\nprint(\"F1 Score:\", f1_score(y_val, probs.astype(int)))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-30T20:18:31.043416Z","iopub.execute_input":"2023-12-30T20:18:31.043755Z","iopub.status.idle":"2023-12-30T20:18:31.090293Z","shell.execute_reply.started":"2023-12-30T20:18:31.043724Z","shell.execute_reply":"2023-12-30T20:18:31.089278Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion Matrix using new threshold\ncm = confusion_matrix(y_val, probs.astype(int))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-30T20:18:31.091929Z","iopub.execute_input":"2023-12-30T20:18:31.092733Z","iopub.status.idle":"2023-12-30T20:18:31.346188Z","shell.execute_reply.started":"2023-12-30T20:18:31.092688Z","shell.execute_reply":"2023-12-30T20:18:31.345055Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **<center><span style=\"color:RebeccaPurple;\">Player Evaluation</span></center>**\n***","metadata":{}},{"cell_type":"markdown","source":"Now that our model demonstrates reliable prediction capabilities, our focus shifts to evaluating players' tackling performances. Given the inherent variance in tackling opportunities across positions, our analysis centers on comparing players within their respective positions to derive meaningful insights. The first plot showcases the top 5 players within each position based on their total number of tackles. The second plot features these same players, presenting their tackle success ratio. This ratio is derived from the player's total tackle count against their expected tackle count, calculated as the summation of their predicted probabilities obtained from our model. In our assessment, a success ratio of 1.0 denotes an expected performance level. Ratios below this benchmark indicate underperformance by the player of interest, while those above signify overperformance within the set criteria.","metadata":{}},{"cell_type":"code","source":"# Make Predictions using model\npred_probs = xgb_model.predict_proba(final[features])[:, 1]\n# Probabilty of tackle\nfinal['pred_probs'] = pred_probs\n# Actual Tackle Prediction\nfinal['preds'] = np.where(final['pred_probs'] > best_threshold, 1, 0)\n\nplayer_predictions = final.groupby('nflId_tack').sum()[['success', 'pred_probs', 'preds']]\n\n# Player names with predictions\nname_preds = pd.merge(player_predictions, player_data[['nflId', 'displayName', 'position']], left_on='nflId_tack', right_on='nflId')\nname_preds['success_diff'] = name_preds['success'] - name_preds['preds']\nname_preds['probs_ratio'] = name_preds['success'] / name_preds['pred_probs']","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-30T20:18:31.347601Z","iopub.execute_input":"2023-12-30T20:18:31.348527Z","iopub.status.idle":"2023-12-30T20:18:31.427452Z","shell.execute_reply.started":"2023-12-30T20:18:31.348492Z","shell.execute_reply":"2023-12-30T20:18:31.426154Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Top 5 players by number of tackles by position\ntop_players_by_position = tackle_final.groupby('position').apply(lambda x: x.nlargest(5, 'success_sum'))\nmax_success_sums = top_players_by_position.groupby(level=0)['success_sum'].max()\nsorted_positions = max_success_sums.sort_values(ascending=False).index\n\nfig, axes = plt.subplots(nrows=len(sorted_positions), figsize=(12, 10), sharex=True)\n\n# Plotting the top 5 players by position as horizontal bar charts\nfor i, position in enumerate(sorted_positions):\n    data = top_players_by_position.loc[position]\n    sorted_data = data.sort_values('success_sum')  # Sort data within each subplot\n    \n    ax = axes[i] if len(sorted_positions) > 1 else axes  # Handle single subplot case\n    bars = ax.barh(sorted_data['displayName'], sorted_data['success_sum'], color='#6A0DAD')\n    ax.set_title(f'{position}', fontsize=10)\n    ax.set_xlabel('Tackles', fontsize=10)\n    ax.tick_params(axis='y', which='major', labelsize=8)  # Adjust label size for better readability\n\n    # Annotate bars with their respective 'success_sum' values\n    for bar, value in zip(bars, sorted_data['success_sum']):\n        ax.text(bar.get_width(), bar.get_y() + bar.get_height() / 2, str(value),\n                va='center', ha='left', color='black', fontsize=8)\n\n# Add a figure title\nfig.suptitle('Top 5 Players in Number of Tackles by Position', fontsize=12, x = 0.545, y=0.95)\n\n        \nplt.tight_layout(pad=3.0)  # Increase spacing between subplots\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-30T20:18:32.722733Z","iopub.execute_input":"2023-12-30T20:18:32.723086Z","iopub.status.idle":"2023-12-30T20:18:34.375868Z","shell.execute_reply.started":"2023-12-30T20:18:32.723052Z","shell.execute_reply":"2023-12-30T20:18:34.374539Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(nrows=len(sorted_positions), figsize=(12, 10), sharex=True)\n\n# Plotting the top 5 players by position as horizontal bar charts\nfor i, position in enumerate(sorted_positions):\n    data = top_players_by_position.loc[position]\n    sorted_data = data.sort_values('success_sum')  # Sort data within each subplot\n    \n    ax = axes[i] if len(sorted_positions) > 1 else axes  # Handle single subplot case\n    ratios = name_preds.loc[name_preds['displayName'].isin(sorted_data['displayName'].tolist())]['probs_ratio'].sort_values()\n    bars = ax.barh(sorted_data['displayName'], ratios, color='#6A0DAD')\n    ax.set_title(f'{position}', fontsize=10)\n    ax.set_xlabel('Success Ratio', fontsize=10)\n    ax.tick_params(axis='y', which='major', labelsize=8)  # Adjust label size for better readability\n\n    # Annotate bars with their respective 'success_sum' values\n    for bar, value in zip(bars, ratios):\n        ax.text(bar.get_width(), bar.get_y() + bar.get_height() / 2, str(round(value, 2)),\n                va='center', ha='left', color='black', fontsize=9)\n        \n    # Add a vertical dotted line at zero\n    ax.axvline(x=1, color='black', linestyle='--', linewidth=0.8)\n        \n# Add a figure title\nfig.suptitle('Top 5 Players in Success Ratio by Position', fontsize=12, x=0.545, y=0.95)        \n\nplt.tight_layout(pad=3.0)  # Increase spacing between subplots\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-30T20:53:42.145272Z","iopub.execute_input":"2023-12-30T20:53:42.145925Z","iopub.status.idle":"2023-12-30T20:53:43.938486Z","shell.execute_reply.started":"2023-12-30T20:53:42.145863Z","shell.execute_reply":"2023-12-30T20:53:43.937599Z"},"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The comparison based solely on the total number of tackles among the top 5 players in each position shows a general similarity in performance. However, when evaluating their tackle success ratio, a more nuanced view emerges. Consider Inside Linebackers (ILB), where the range among players is only 5 tackles. Yet, analyzing their success ratios reveals disparities: Raashan Evans and Roquan Smith underperform compared to C.J. Mosley, who demonstrates an overperformance trend. This paints a much different picture than simple box scores which make these players appear to perform similarly. The most notable differences emerge among Defensive Ends (DE). Derrick Brown notably exceeds expectations, completing over twice the expected tackles, while Cameron Jordan falls significantly short, accomplishing less than half of the expected tackles. In summary, our model serves as a metric for comparing player performance, offering detailed insights that uncover substantial variations in tackling abilities, unrepresented by conventional box score metrics.","metadata":{}}]}